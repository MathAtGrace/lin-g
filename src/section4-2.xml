<?xml version="1.0" encoding="UTF-8"?>

<section xml:id="sec-eigen-find"
	 xmlns:xi="http://www.w3.org/2001/XInclude">

  <title> Finding eigenvalues and eigenvectors </title>

  <introduction>
    <p> The last section introduced eigenvalues and eigenvectors,
    presented the underlying geometric intuition behind their
    definition, and demonstrated their use in understanding the
    long-term behavior of certain systems.  We will now develop a
    more algebraic understanding of eigenvalues and eigenvectors.  In
    particular, we will find an algebraic method for determining the
    eigenvalues and eigenvectors of a square matrix.  </p>

    <exploration>
      <statement>
      <p> Let's begin by reviewing some important ideas that we have
      seen previously.  
      <ol label="a.">
	<li><p> Suppose that <m>A</m> is a square matrix and that
	the nonzero vector <m>\xvec</m> is a solution to
	the homogeneous equation <m>A\xvec = \zerovec</m>.  What can
	we conclude about the invertibility of <m>A</m>?  </p></li>

	<li><p> How does the determinant <m>\det A</m> tell us if
	there is a nonzero solution to the homogeneous equation
	<m>A\xvec = \zerovec</m>? </p></li>

	<li><p> Suppose that
	<me>
	  A = \left[\begin{array}{rrr}
	  3 \amp -1 \amp 1 \\
	  0 \amp 2 \amp 4 \\
	  1 \amp 1 \amp 3 \\
	  \end{array}\right]
	</me>.
	Find the determinant <m>\det A</m>.  What does this tell us
	about the solution space to the homogeneous equation <m>A\xvec
	= \zerovec</m>? </p></li>

	<li><p> FInd a basis for <m>\nul(A)</m>.</p></li>

	<li><p> What is the relationship between the rank of a matrix
	and the dimension of its null space? </p></li>
      </ol></p>
      </statement>

      <solution>
	<p><ol label="a.">
	  <li><p> The matrix cannot have a pivot position in every
	  column so it is not invertible. </p></li>

	  <li><p> If there is a nonzero solution to the homogeneous
	  equation <m>A\xvec=\zerovec</m>, then <m>A</m> is not
	  invertible so <m>\det A = 0</m>. </p></li>

	  <li><p> We find that <m>\det A = 0</m> so there is a nonzero
	  solution to the homogeneous equation. </p></li>

	  <li><p> The reduced row echelon form of <m>A</m> is
	  <me>
	    \left[\begin{array}{rrr}
	    1 \amp 0 \amp 1 \\
	    0 \amp 1 \amp 2 \\
	    0 \amp 0 \amp 0 \\
	    \end{array}\right]
	  </me>
	  so the solution space to the homogeneous equation may be
	  described parametrically as
	  <m>x=x_3\threevec{-1}{-2}{1}</m>.  A basis for
	  <m>\nul(A)</m> is therefore
	  <m>\threevec{-1}{-2}{1}</m>. </p></li>

	  <li><p> If the matrix <m>A</m> has <m>n</m> columns, then
	  <m>\dim~\nul(A) = n-\rank(A)</m>. </p></li>

	</ol></p>
      </solution>
    </exploration>

  </introduction>

  <subsection>
    <title> The characteristic polynomial </title>

    <p> We will first see that the eigenvalues of a square matrix
    appear as the roots of a particular polynomial.  To begin, notice
    that we originally defined an eigenvector as a nonzero vector
    <m>\vvec</m> that satisfied the equation <m>A\vvec =
    \lambda\vvec</m>.  We will rewrite this as
    <me>
      \begin{aligned}
      A\vvec \amp {}={} \lambda\vvec \\
      A\vvec - \lambda\vvec \amp {}={} \zerovec \\
      A\vvec - \lambda I\vvec \amp {}={} \zerovec \\
      (A-\lambda I)\vvec \amp {}={} \zerovec\text{.} \\
      \end{aligned}
    </me>
    In other words, an eigenvector <m>\vvec</m> is a solution of the
    homogeneous equation <m>(A-\lambda I)\vvec=\zerovec</m>.  This
    puts us in familiar territory, which we will explore in the next
    activity.
    </p>

    <activity>
      <statement>
      <p> The eigenvalues of a square matrix are defined by the
      condition that there be a nonzero solution to the homogeneous
      equation <m>(A-\lambda I)\vvec=\zerovec</m>.
      <ol label="a.">
	<li><p> If there is a nonzero solution to the homogeneous
	equation <m>(A-\lambda I)\vvec = \zerovec</m>, what can we
	conclude about the invertibility of the matrix <m>A-\lambda
	I</m>? </p></li>

	<li><p> If there is a nonzero solution to the homogeneous
	equation <m>(A-\lambda I)\vvec = \zerovec</m>, what can we
	conclude about the determinant <m>\det(A-\lambda I)</m>?
	</p></li>

	<li><p> Let's consider the matrix 
	<me>
	  A = \left[\begin{array}{rr}
	  1 \amp 2 \\
	  2 \amp 1 \\
	  \end{array}\right]
	</me>
	from which we construct
	<me>
	  A-\lambda I =
	  \left[\begin{array}{rr}
	  1 \amp 2 \\
	  2 \amp 1 \\
	  \end{array}\right]
	  - \lambda 
	  \left[\begin{array}{rr}
	  1 \amp 0 \\
	  0 \amp 1 \\
	  \end{array}\right]
	  =
	  \left[\begin{array}{rr}
	  1-\lambda \amp 2 \\
	  2 \amp 1-\lambda \\
	  \end{array}\right]
	</me>.
	Find the determinant <m>\det(A-\lambda I)</m>.  What kind of
	equation do you obtain when we set this determinant to zero to
	obtain <m>\det(A-\lambda I) = 0</m>? </p></li>

	<li><p> Use the determinant you found in the previous part to
	find the eigenvalues <m>\lambda</m> by solving
	<m>\det(A-\lambda I) = 0</m>.  We considered this matrix in
	the previous section so we should find the same eigenvalues
	for <m>A</m> that we found by reasoning geometrically
	there. </p></li> 

	<li><p> Consider the matrix
	<m>A = \left[\begin{array}{rr}
	2 \amp 1 \\
	0 \amp 2 \\
	\end{array}\right]
	</m> and find its eigenvalues by solving the equation
	<m>\det(A-\lambda I) = 0</m>. </p></li>

	<li><p> Consider the matrix
	<m>A = \left[\begin{array}{rr}
	0 \amp -1 \\
	1 \amp 0 \\
	\end{array}\right]
	</m> and find its eigenvalues by solving the equation
	<m>\det(A-\lambda I) = 0</m>. </p></li>

	<li><p> Find the eigenvalues of the triangular matrix
	<m>
	  \left[\begin{array}{rrr}
	  3 \amp -1 \amp 4 \\
	  0 \amp -2 \amp 3 \\
	  0 \amp 0 \amp 1 \\
	  \end{array}\right]
	</m>.  What is generally true about the eigenvalues of a
	triangular matrix? </p></li>
      </ol>
      </p>
      </statement>

      <solution>
	<p>
	  The solutions to this activity are given in the text
	  below.
	</p>
      </solution>
    </activity>

    <p> This activity demonstrates a technique that enables us to find
    the eigenvalues of a square matrix <m>A</m>.  Since an eigenvalue
    <m>\lambda</m> is a scalar for which the equation <m>(A-\lambda
    I)\vvec = \zerovec</m> has a nonzero solution, it must be the case
    that <m>A-\lambda I</m> is not invertible.  Therefore, its
    determinant is zero.  This gives us the equation
    <me>
      \det(A-\lambda I) = 0
    </me>
    whose solutions are the eigenvalues of <m>A</m>.  This equation is
    called the <em>characteristic equation</em> of <m>A</m>.
    <idx> characteristic equation </idx>
    </p>

    <p> If we write the characteristic equation for the matrix
    <m> A = \left[\begin{array}{rr}
    1 \amp 2 \\
    2 \amp 1 \\
    \end{array}\right]
    </m>, we see that
    <me>
      \begin{aligned}
      \det(A-\lambda I) \amp {}={} 0 \\
      \\
      \det \left[\begin{array}{rr}
      1 - \lambda \amp 2 \\
      2 \amp 1 - \lambda \\
      \end{array}\right] \amp {}={} 0 \\
      \\
      (1-\lambda)^2 - 4 \amp {}={}  0 \\
      -3 - 2\lambda + \lambda^2 {}={} 0 \\
      (3-\lambda)(-1-\lambda) {}={} 0\text{.} \\
      \end{aligned}
    </me>
    This shows us that the eigenvalues are <m>\lambda = 3</m> and
    <m>\lambda=-1</m>, the same eigenvalues we found by
    reasoning geometrically in the previous section.
    </p>

    <p> <idx> characteristic polynomial </idx>
    In general, the expression <m>\det(A-\lambda I)</m> is a
    polynomial in <m>\lambda</m>, which is called the
    <em>characteristic polynomial</em> of <m>A</m>.  If <m>A</m> is an
    <m>n\times n</m> matrix, the degree of the characteristic
    polynomial is <m>n</m>.  For instance, if <m>A</m> is a
    <m>2\times2</m> matrix, then <m>\det(A-\lambda I)</m> is a
    quadratic polynomial; if <m>A</m> is a <m>3\times3</m> matrix,
    then <m>\det(A-\lambda I)</m> is a cubic polynomial. </p>

    <p> The other examples that appear in this activity demonstrate
    some issues we will need to deal with later.  For instance, the
    matrix
    <m>A = \left[\begin{array}{rr}
    2 \amp 1 \\
    0 \amp 2 \\
    \end{array}\right]
    </m>
    leads to the characteristic equation, <m>(2-\lambda)^2 = 0</m>.
    In this case, there is only one eigenvalue <m>\lambda = 2</m> that
    appears as a repeated root.  For now, we simply note that our work in
    the previous section showed that it was not possible to form a
    basis of <m>\real^2</m> consisting of eigenvectors of <m>A</m>.  </p>

    <p> Finally, when
    <m>
      A = \left[\begin{array}{rr}
      0 \amp -1 \\
      1 \amp 0 \\
      \end{array}\right]
    </m>, we find the characteristic equation <m>\lambda^2 + 1 =
    0</m>.  While this equation has no real solutions, it does have
    complex solutions <m>\lambda = \pm i</m>, and it will be useful
    for us to work with these complex eigenvalues in the future.  In
    the meantime, remember that this matrix defines a <m>90^\circ</m>
    rotation so we do not expect any solutions to the equation
    <m>A\vvec = \lambda \vvec</m> for real eigenvalues <m>\lambda</m>
    since a vector <m>\vvec</m> and <m>A\vvec</m> can never lie on the
    same line. </p>

    <p> Finally, the eigenvalues of a triangular matrix are easily
    determined because the
    determinant of a triangular matrix is the product of the entries
    on the diagonal.  Therefore, the characteristic equation is
    <me>
      \begin{aligned}
      \det\left(
      \left[\begin{array}{rrr}
      3 \amp -1 \amp 4 \\
      0 \amp -2 \amp 3 \\
      0 \amp 0 \amp 1 \\
      \end{array}\right]
      -\lambda I\right) \amp {}={}
      \det
      \left[\begin{array}{rrr}
      3-\lambda \amp -1 \amp 4 \\
      0 \amp -2-\lambda \amp 3 \\
      0 \amp 0 \amp 1-\lambda \\
      \end{array}\right] \\
      \\
      \amp {}={}(3-\lambda)(-2-\lambda)(1-\lambda) = 0\text{,}
      \end{aligned}
    </me>
    showing that the eigenvalues are the diagonal entries <m>\lambda =
    3,-2,1</m>. 
    </p>

    <p> We have how seen now the characteristic equation can be used
    to determine the eigenvalues of a matrix.  Remember, however,
    that finding the determinant of a matrix using a co-factor
    expansion is not computationally feasible when the size of the
    matrix is relatively large.  Finding the eigenvalues of a matrix
    by factoring its characteristic polynomial is therefore a
    technique limited to relatively small matrices; we will introduce a
    new technique for finding eigenvalues of larger matrices in the
    next chapter.</p>
      
  </subsection>

  <subsection>
    <title> Finding eigenvectors </title>

    <p> Now that we can find the eigenvalues of a square matrix
    <m>A</m> by solving the characteristic equation <m>\det(A-\lambda
    I) = 0</m>, we will turn to the question of finding the
    eigenvectors associated to an eigenvalue <m>\lambda</m>. Once
    again, the key is to note that an eigenvector is a nonzero
    solution to the homogeneous equation <m>(A-\lambda I)\vvec =
    \zerovec</m>.  In other words, the eigenvectors associated to an
    eigenvalue <m>\lambda</m> form the null space <m>\nul(A-\lambda
    I)</m>. </p>

    <p> This shows that the eigenvectors associated to an eigenvalue
    form a subspace of <m>\real^n</m>.  We will use <m>E_\lambda</m>
    to denote the subspace of eigenvectors of a matrix <m>A</m>
    associated to the eigenvalue <m>\lambda</m> and note that
    <me>
      E_\lambda = \nul(A-\lambda I)
    </me>.
    We say that <m>E_\lambda</m> is the <em>eigenspace</em> of
    <m>A</m> associated 
    to the eigenvalue <m>\lambda</m>.
    <idx> eigenspace </idx>
    </p>
    
    <activity>
      <statement>
      <p> In this activity, we will find the eigenvectors of a matrix
      as the null space of the matrix <m>A-\lambda I</m>.
      <ol label="a.">
	<li><p> Let's begin with the matrix
	<m>
	  A = \left[\begin{array}{rr}
	  1 \amp 2 \\
	  2 \amp 1 \\
	  \end{array}\right]
	</m>.  We have seen that <m>\lambda = 3</m> is an eigenvalue.
	Form the matrix <m>A-3I</m> and find a basis for the
	eigenspace <m>E_3 = \nul(A-3I)</m>.
	What is the dimension of this eigenspace?
	For each of the basis vectors <m>\vvec</m>, verify
	that <m>A\vvec = 3\vvec</m>. </p></li>

	<li><p> We also saw that <m>\lambda = -1</m> is an
	eigenvalue.  Form the matrix <m>A-(-1)I</m> and find a basis
	for the eigenspace <m>E_{-1}</m>.  What is the dimension of
	this eigenspace? 
	For each of the basis vectors
	<m>\vvec</m>, verify that <m>A\vvec = -\vvec</m>. </p></li>

	<li><p> Is it possible to form a basis of <m>\real^2</m>
	consisting of eigenvectors of <m>A</m>? </p></li>

	<li><p> Now consider the matrix
	<m>A = \left[\begin{array}{rr}
	3 \amp 0 \\
	0 \amp 3 \\
	\end{array}\right]
	</m>.  Write the characteristic equation for <m>A</m> and use
	it to find the eigenvalues of <m>A</m>.  For each eigenvalue,
	find a basis for its eigenspace <m>E_\lambda</m>.  Is it
	possible to form a basis of <m>\real^2</m> consisting of
	eigenvectors of <m>A</m>? </p></li>

	<li><p> Next, consider the matrix
	<m>A = \left[\begin{array}{rr}
	2 \amp 1 \\
	0 \amp 2 \\
	\end{array}\right]
	</m>.  Write the characteristic equation for <m>A</m> and use
	it to find the eigenvalues of <m>A</m>.  For each eigenvalue,
	find a basis for its eigenspace <m>E_\lambda</m>.  Is it
	possible to form a basis of <m>\real^2</m> consisting of
	eigenvectors of <m>A</m>? </p></li>

	<li><p> Finally, find the eigenvalues and eigenvectors of the
	diagonal matrix  
	<m>
	  A = \left[\begin{array}{rr}
	  4 \amp 0 \\
	  0 \amp -1 \\
	  \end{array}\right]
	</m>.  Explain your result by considering the geometric effect
	of the matrix transformation defined by <m>A</m>. </p></li>
      </ol>
      </p>
      </statement>

      <solution>
	<p><ol label="a.">
	  <li><p> We have
	  <me>
	    A - 3I =
	    \mattwo{-2}{2}{2}{-2}
	    \sim
	    \mattwo{1}{-1}{0}{0}\text{.}
	  </me>
	  The null space <m>\nul(A-3I)</m> is one-dimensional with
	  basis <m>\twovec{1}{1}</m>.
	  </p></li>

	  <li><p> We have
	  <me>
	    A - (-1)I =
	    \mattwo{2}{2}{2}{2}
	    \sim
	    \mattwo{1}{1}{0}{0}\text{.}
	  </me>
	  The null space <m>\nul(A+I)</m> is one-dimensional with
	  basis <m>\twovec{-1}{1}</m>.
	  </p></li>

	  <li><p> We can form a basis for <m>\real^2</m> consisting of
	  eigenvectors of <m>A</m> by taking <m>\left\{\twovec{1}{1},
	  \twovec{-1}{1}\right\}</m>.
	  </p></li>

	  <li><p> The characteristic equation is <m>(3-\lambda)^2 =
	  0</m>, which means that there is a single eigenvalue
	  <m>\lambda=3</m>.  This eigenspace is two-dimensional with
	  basis <m>\left\{\twovec{1}{0},\twovec{0}{1}\right\}</m>.  In
	  this case, 
	  we can form a basis for <m>\real^2</m> consisting of
	  eigenvectors of <m>A</m>.
	  </p></li>

	  <li><p> The characteristic equation is <m>(2-\lambda)^2 =
	  0</m> so there is again a single eigenvalue
	  <m>\lambda=2</m>.  In this case, the eigenspace is
	  one-dimensional with basis vector <m>\twovec{1}{0}</m>.  It
	  is not possible to form a basis for <m>\real^2</m>
	  consisting of eigenvectors.
	  </p></li>

	  <li><p> We have eigenvectors <m>\twovec10</m> with
	  associated eigenvector <m>\lambda=4</m> and <m>\twovec01</m>
	  with associated eigenvector <m>\lambda=-1</m>.
	  </p></li>
	</ol></p>
      </solution>
	    
    </activity>

    <p> Once we find the eigenvalues of a matrix <m>A</m>, describing
    the eigenspace <m>E_\lambda</m> amounts to the familiar task of
    describing the null space <m>\nul(A-\lambda I)</m>.  For instance,
    we know that
    <m>\lambda = 3</m>
    is an eigenvalue of
    <m>
      A = \left[\begin{array}{rr}
      1 \amp 2 \\
      2 \amp 1 \\
      \end{array}\right]
    </m>.
    Then,
    <m>E_3 = \nul(A-3I)</m>, and we have
    <me>
      A - 3I =
      \left[\begin{array}{rr}
      -2 \amp 2 \\
      2 \amp -2 \\
      \end{array}\right]
      \sim
      \left[\begin{array}{rr}
      1 \amp -1 \\
      0 \amp 0 \\
      \end{array}\right]\text{.}
    </me>
    From the reduced row echelon form, we see that the eigenvectors
    <m>\vvec = \twovec{v_1}{v_2}</m> are determined by the single
    equation <m>v_1-v_2 = 0</m> or <m>v_1 = v_2</m>.  Therefore the
    eigenvectors in <m>E_3</m> have the form
    <me>
      \vvec=\twovec{v_1}{v_2} = \twovec{v_2}{v_2} = v_2\twovec{1}{1}
    </me>.
    In other words, <m>E_3</m> is a one-dimensional subspace of
    <m>\real^2</m> with basis <m>\twovec{1}{1}</m>.  Once again, this
    agrees with the eigenvectors that we found geometrically in the
    previous section.
    </p>

    <p> The same reasoning applies to show that the eigenvectors
    associated to <m>\lambda = -1</m> have the form
    <me>
      \vvec = v_2\twovec{-1}{1}
    </me>,
    which shows that the eigenspace
    <m>E_{-1}</m> is a one-dimensional subspace of <m>\real^2</m>
    having basis <m>\twovec{-1}{1}</m>.
    </p>

    <p> Two more examples from the activity are important.  The
    characteristic equation for the matrix
    <m>A=
    \left[\begin{array}{rr}
    3 \amp 0 \\
    0 \amp 3 \\
    \end{array}\right]
    </m>
    is <m>\det(A-\lambda I) = (3-\lambda)^2 = 0</m>.  This shows that
    there is a single eigenvalue <m>\lambda = 3</m>.  If we find the
    eigenspace <m>E_3=\nul(A-3I)</m>, we have
    <me>
      A -3I = 
      \left[\begin{array}{rr}
      3 \amp 0 \\
      0 \amp 3 \\
      \end{array}\right]
      - 3I
      =
      \left[\begin{array}{rr}
      0 \amp 0 \\
      0 \amp 0 \\
      \end{array}\right]
    </me>.
    This shows that every vector is in <m>E_3</m> so that
    <m>E_3=\real^2</m>.  In this case, there is a basis of
    <m>\real^2</m> consisting of eigenvectors of <m>A</m>.  This
    aligns with our geometric understanding:  this matrix has the
    effect of scaling vectors by a factor of <m>3</m> in every direction.
    Therefore, every vector is an eigenvector with eigenvalue
    <m>\lambda = 3</m>.
    </p>

    <p> However, if we consider the matrix
    <m>A=
    \left[\begin{array}{rr}
    2 \amp 1 \\
    0 \amp 2 \\
    \end{array}\right]
    </m>,
    we find the characteristic equation <m>(2-\lambda)^2 = 0</m>,
    which shows that there is again a single eigenvalue <m>\lambda =
    2</m>.  In this case,
    <me>
      A -2I = 
      \left[\begin{array}{rr}
      2 \amp 1 \\
      0 \amp 2 \\
      \end{array}\right]
      - 2I
      =
      \left[\begin{array}{rr}
      0 \amp 1 \\
      0 \amp 0 \\
      \end{array}\right]
    </me>,
    which shows that <m>E_2</m> is a one-dimensional subspace of
    <m>\real^2</m> with basis <m>\twovec{1}{0}</m>.  Since there are
    no other eigenvalues, it is not possible to find a basis for
    <m>\real^2</m> consisting of eigenvectors of <m>A</m>. </p>

    <p> Once again, we can understand this result geometrically.  The
    matrix transformation corresponding to the matrix <m>A</m> is a
    shear that slides vectors horizontally.  This transformation
    therefore only
    scales vectors that lie on the horizontal axis.
    </p>

    <p> These last two examples illustrate two types of behavior when
    there is a single eigenvalue.  In one case, we are able to
    construct a basis of <m>\real^2</m> using eigenvectors;  in the
    other, we are not. 
    We will explore this behavior more in the next subsection. </p>

    <assemblage>
      <title> A check on our work </title>

      <p> When finding eigenvalues and their associated
      eigenvectors in this way, we first find eigenvalues
      <m>\lambda</m> by solving the characteristic equation.  If
      <m>\lambda</m> is a solution to the characteristic equation,
      then <m>A-\lambda I</m> is not invertible and, consequently, 
      <m>A-\lambda I</m> must contain a row
      without a pivot position.</p>

      <p> This serves as a check on our work.  If we row reduce
      <m>A-\lambda I</m> and find the identity matrix, then we have
      made an error either in solving the characteristic equation or
      in finding <m>\nul(A-\lambda I)</m>.
      </p>
    </assemblage>
    
  </subsection>

  <subsection>
    <title> The characteristic polynomial and the dimension of
    eigenspaces </title> 

    <p> Given a square
    <m>n\times n</m> matrix <m>A</m>, we saw in the previous section
    the value of being able to express any vector in <m>\real^n</m> as
    a linear 
    combination of eigenvectors of <m>A</m>.  For this reason, we
    asked <xref ref="question-eigen-basis" /> to determine
    when we can construct a basis of <m>\real^n</m> consisting of
    eigenvectors.  We will explore this question more fully now. </p>

    <p> As we saw above, the eigenvalues of <m>A</m> are the solutions
    of the characteristic equation <m>\det(A-\lambda I) = 0</m>.  Two
    examples of characteristic equations we have seen above are
    <me>
      \begin{aligned}
      (3-\lambda)(-2-\lambda)(1-\lambda) \amp {}={} 0 \\
      \text{and}\qquad(2-\lambda)^2 \amp {}={} 0 \\
      \end{aligned}
    </me>.
    Generally speaking, the characteristic polynomial can always be
    factored into terms having the form
    <m>(\lambda_j-\lambda)</m> where <m>\lambda_j</m> is an eigenvalue
    of <m>A</m>.  In doing so, we must allow ourselves to consider
    complex eigenvalues, which we will study in more detail in the
    next section.  This means, however, that we can always write the
    characteristic equation in the form
    <me>
      (\lambda_1-\lambda)^{m_1}
      (\lambda_2-\lambda)^{m_2}
      \ldots
      (\lambda_p-\lambda)^{m_p}
      = 0
    </me>.
    The solutions to the characteristic equation are the eigenvalues
    <m>\lambda_j</m>, and <m>m_j</m>, the number of times that
    <m>\lambda_j - \lambda</m> appears as a factor in the
    characteristic polynomial, is called the <em>multiplicity</em> of the
    eigenvalue <m>\lambda_j</m>.
    <idx> multiplicity </idx>
    </p>

    <example>
      <statement>
	<p> We have seen that the matrix
	<m>A = \left[\begin{array}{rr}
	2 \amp 1 \\
	0 \amp 2 \\
	\end{array}\right]
	</m> has the characteristic equation <m>(2-\lambda)^2 =
	0</m>.  This matrix <m>A</m> has a single eigenvalue
	<m>\lambda = 2</m>, which has multiplicity <m>2</m>. </p>
      </statement>
    </example>

    <example>
      <statement>
	<p> If a matrix has the characteristic equation
	<me>
	  (4-\lambda)^2(-5-\lambda)(1-\lambda)^7(3-\lambda)^2 = 0
	</me>,
	then that matrix has four eigenvalues:  <m>\lambda=4</m>
	having multiplicity 2; <m>\lambda=-5</m> having multiplicity
	1; <m>\lambda=1</m> having multiplicty 7; and <m>\lambda=3</m>
	having multiplicty 2.  The degree of the characteristic
	polynomial is the sum of the multiplicities <m>2+1+7+2 =
	12</m> so this matrix must be a <m>12\times12</m>
	matrix. </p>
      </statement>
    </example>

    <p> The multiplicities of the eigenvalues are important because
    they influence the dimension of the eigenspaces.  We know that the
    dimension of an eigenspace must be at least one; the following
    proposition also tells us the dimension of an eigenspace can be no
    larger than the multiplicity of its associated eigenvalue. </p>

    <proposition xml:id="prop-eigen-basis" >
      <statement>
	<p> If <m>\lambda</m> is a real eigenvalue of the matrix
	<m>A</m> with multiplicity <m>m</m>, then
	<me>
	  1 \leq \dim E_\lambda \leq m
	  </me>.
	  </p>
      </statement>
    </proposition>

    <example>
      <statement>
	<p> The diagonal matrix
	<m>\left[\begin{array}{rr}
	3 \amp 0 \\
	0 \amp 3 \\
	\end{array}\right]
	</m> has the characteristic equation <m>(3-\lambda)^2 =
	0</m>.  There is a single eigenvalue <m>\lambda = 3</m> having
	multiplicity <m>m = 2</m>, and we saw earlier that
	<m>\dim E_3 = 2 \leq m = 2</m>.
	</p>
      </statement>
    </example>

    <example>
      <statement>
	<p>The matrix
	<m>\left[\begin{array}{rr}
	2 \amp 1 \\
	0 \amp 2 \\
	\end{array}\right]
	</m> has the characteristic equation <m>(2-\lambda)^2 =
	0</m>.  Once again, there is a single eigenvalue <m>\lambda =
	2</m> having 
	multiplicity <m>m = 2</m>.  In contrast with the previous
	example, we saw that
	<m>\dim E_2 = 1 \leq m = 2</m>.
	</p>
      </statement>
    </example>

    <example>
      <statement>
	<p> We saw earlier that the matrix
	<m>
	  \left[\begin{array}{rrr}
	  3 \amp -1 \amp 4 \\
	  0 \amp -2 \amp 3 \\
	  0 \amp 0 \amp 1 \\
	  \end{array}\right]
	</m> has the characteristic equation
	<me>(3-\lambda)(-2-\lambda)(1-\lambda)=0</me>.
	There are three eigenvalues <m>\lambda=3,-2,1</m> each having
	multiplicity <m>1</m>.  By the proposition, we are guaranteed
	that the dimension of each eigenspace is <m>1</m>;  that is,
	<me>
	  \dim E_3 = \dim E_{-2} = \dim E_1 = 1
	</me>.
	It turns out that this is enough to guarantee that there is a
	basis of <m>\real^3</m> consisting of eigenvectors. </p>
      </statement>
    </example>

    <example>
      <statement>
	<p> If a <m>12\times12</m> matrix has the characteristic
	equation 
	<me>
	  (4-\lambda)^2(-5-\lambda)(1-\lambda)^7(3-\lambda)^2 = 0
	</me>,
	we know there are four eigenvalues <m>\lambda=4,-5,1,3</m>.
	Without more information, all we can say about the dimensions
	of the eigenspaces is 
	<me>
	  \begin{aligned}
	  1 \leq \dim E_4 \amp {}\leq{} 2 \\
	  1 \leq \dim E_{-5} \amp {}\leq{} 1 \\
	  1 \leq \dim E_1 \amp {}\leq{} 7 \\
	  1 \leq \dim E_3 \amp {}\leq{} 2\text{.} \\
	  \end{aligned}
	</me>
	We can guarantee that <m>\dim E_{-5} = 1</m>, but we cannot be
	more specific about the dimensions of the other eigenspaces.
	</p>
      </statement>
    </example>

    <p> Fortunately, if we have an <m>n\times n</m> matrix, it most
    commonly happens that the characteristic equation has the form
    <me>
      (\lambda_1-\lambda)
      (\lambda_2-\lambda)
      \ldots
      (\lambda_n-\lambda) = 0
    </me>
    where there are <m>n</m> distinct eigenvalues, each of which
    has multiplicity <m>1</m>.  In this case, the dimension of each of
    the eigenspaces <m>\dim E_{\lambda_j} = 1</m>.  With a little
    work, it can be seen that choosing a basis vector <m>\vvec_j</m> for
    each of the eigenspaces produces a basis for <m>\real^n</m>.  We
    therefore have the following proposition. </p>

    <proposition>
      <statement>
	<p> If <m>A</m> is an <m>n\times n</m> matrix having <m>n</m>
	distinct real eigenvalues, then there is a basis of <m>\real^n</m>
	consisting of eigenvectors of <m>A</m>.</p>
      </statement>
    </proposition>

    <p> This proposition provides one answer to our <xref
    ref="question-eigen-basis" />.  The next activity explores this
    question further. </p>
	
    <activity>
      <statement>
      <p>
	<ol label="a.">
	  <li><p> Identify the eigenvalues, and their multiplicities,
	  of an <m>n\times n</m>
	  matrix whose characteristic polynomial is
	  <m>(2-\lambda)^3(-3-\lambda)^{10}(5-\lambda)</m>.  What can you
	  conclude about the dimensions of the eigenspaces?  What is the
	  dimension of the matrix?  Do you have enough information to
	  guarantee that there is a basis of <m>\real^n</m> consisting
	  of eigenvectors? </p></li>

	  <li><p> Find the eigenvalues of 
	  <m>
	    \left[\begin{array}{rr}
	    0 \amp -1 \\
	    4 \amp -4 \\
	    \end{array}\right]
	  </m> and state their multiplicities.  Can you find a basis
	  of <m>\real^2</m> consisting of eigenvectors of this matrix?
	  </p></li>
	  
	  <li><p> Consider the matrix
	  <m>A =
	  \left[\begin{array}{rrr}
	  -1 \amp 0 \amp 2 \\
	  -2 \amp -2 \amp -4 \\
	  0 \amp 0 \amp -2 \\
	  \end{array}\right]
	  </m> whose characteristic equation is
	  <me>
	    (-2-\lambda)^2(-1-\lambda) = 0
	  </me>.
	  <ol label="i.">
	    <li><p> Identify the eigenvalues and their
	    multiplicities. </p></li>

	    <li><p> For each eigenvalue <m>\lambda</m>, find a basis
	    of the eigenspace <m>E_\lambda</m> and state its
	    dimension. </p></li>

	    <li><p> Is there a basis of <m>\real^3</m> consisting of
	    eigenvectors of <m>A</m>?</p></li>
	  </ol></p></li>

	  <li><p> Now consider the matrix
	  <m> A =
	  \left[\begin{array}{rrr}
	  -5 \amp -2 \amp -6 \\
	  -2 \amp -2 \amp -4 \\
	  2 \amp 1 \amp 2 \\
	  \end{array}\right]
	  </m> whose characteristic equation is also
	  <me>
	    (-2-\lambda)^2(-1-\lambda) = 0
	  </me>.
	  <ol label="i.">
	    <li><p> Identify the eigenvalues and their
	    multiplicities. </p></li>

	    <li><p> For each eigenvalue <m>\lambda</m>, find a basis
	    of the eigenspace <m>E_\lambda</m> and state its
	    dimension. </p></li>

	    <li><p> Is there a basis of <m>\real^3</m> consisting of
	    eigenvectors of <m>A</m>?</p></li>
	  </ol></p></li>

	  <li><p> Consider the matrix
	  <m>A = 
	  \left[\begin{array}{rrr}
	  -5 \amp -2 \amp -6 \\
	  4 \amp 1 \amp 8 \\
	  2 \amp 1 \amp 2 \\
	  \end{array}\right]
	  </m> whose characteristic equation is 
	  <me>
	    (-2-\lambda)(1-\lambda)(-1-\lambda) = 0
	  </me>.
	  <ol label="i.">
	    <li><p> Identify the eigenvalues and their
	    multiplicities. </p></li>

	    <li><p> For each eigenvalue <m>\lambda</m>, find a basis
	    of the eigenspace <m>E_\lambda</m> and state its
	    dimension. </p></li>

	    <li><p> Is there a basis of <m>\real^3</m> consisting of
	    eigenvectors of <m>A</m>?</p></li>
	  </ol></p></li>
	  
	</ol>
      </p>
      </statement>

      <solution>
	<p><ol label="a.">
	  <li><p> There are three eigenvalues, <m>\lambda=2</m> has
	  multiplicity <m>3</m>, <m>\lambda=-3</m> has multiplicity
	  <m>10</m>, and <m>\lambda=5</m> has multiplicity <m>1</m>.
	  We know that
	  <me>
	  \begin{aligned}
	  1 \leq \dim E_2 \amp {}\leq{} 3 \\
	  1 \leq \dim E_{-3} \amp {}\leq{} 10 \\
	  1 \leq \dim E_5 \amp {}\leq{} 1\text{.} \\
	  \end{aligned}
	  </me>
	  We can guarantee that <m>\dim E_{5} = 1</m>, but we can say
	  nothing further about the other two eigenspaces.
	</p>

	<p> The dimension of the matrix is <m>14\times14</m> since the
	degree of the characteristic polynomial is <m>14</m>.  We
	cannot guarantee that we can form a basis for
	<m>\real^{14}</m> consisting of eigenvectors, however.
	  </p></li>

	  <li><p> There is one eigenvalue <m>\lambda=-2</m> having
	  multiplicity two.  Because the eigenspace <m>E_{-2}</m> is
	  one-dimensional, however, we cannot find a basis for
	  <m>\real^2</m> consisting of eigenvectors of <m>A</m>.
	  </p></li>

	  <li><p> For the <m>3\times3</m> matrix <m>A</m>,
	  <ol label="i.">
	    <li><p> We have eigenvalues <m>\lambda=-2</m> with
	    multiplicty <m>2</m> and <m>\lambda=-1</m> with multiplicity
	    <m>1</m>.
	    </p></li>

	    <li><p> The eigenspace <m>E_{-2}</m> is two-dimensional
	    with basis
	    <m>\left\{\threevec{-2}{0}{1},\threevec010\right\}</m>.
	    The eigenspace <m>E_{-1}</m> is one-dimensional with basis
	    vector <m>\threevec{-1}20</m>.
	    </p></li>

	    <li><p> We are able to form a
	    basis for <m>\real^3</m> consisting of eigenvectors of
	    <m>A</m>.
	    </p></li>
	  </ol>
	  </p></li>

	  <li><p> For the <m>3\times3</m> matrix <m>A</m>,
	  <ol label="i">
	    <li><p> We have eigenvalues <m>\lambda=-2</m> with
	    multiplicty <m>2</m> and <m>\lambda=-1</m> with multiplicity
	    <m>1</m>.
	    </p></li>

	    <li><p> The eigenspace <m>E_{-2}</m> is one-dimensional
	    with basis vector <m>\threevec{-2}01</m>.  The eigenspace
	    <m>E_{-1}</m> is also one-dimensional with basis vector
	    <m>\threevec{-1}{2}{0}</m>.
	    </p></li>

	    <li><p> It is not possible to form a basis for
	    <m>\real^3</m> consisting of eigenvectors of <m>A</m>.
	    </p></li>
	  </ol>
	  </p></li>

	  <li><p> For this matrix,
	  <ol label="i.">
	    <li><p> There are three eigenvalues <m>\lambda=-2</m>,
	    <m>-1</m>, and <m>1</m>, each having multiplicity
	    <m>1</m>.
	    </p></li>

	    <li><p> A basis vector for the eigenspace <m>E_{-2}</m> is
	    <m>\threevec{-2}01</m>. 
	    A basis vector for the eigenspace <m>E_{-1}</m> is
	    <m>\threevec{1}{-2}0</m>. 
	    A basis vector for the eigenspace <m>E_{1}</m> is
	    <m>\threevec{-2}{3}{1}</m>.
	    </p></li>

	    <li><p> We can form a basis for <m>\real^3</m> consisting
	    of eigenvectors of <m>A</m>.
	    </p></li>
	  </ol>
	  </p></li>
	</ol></p>
      </solution>
	  
    </activity>

  </subsection>

  <subsection>
    <title> Computational issues in finding eigenvalues and
    eigenvectors </title>

    <p> We can use Sage to find the characteristic polynomial,
    eigenvalues, and eigenvectors of a matrix.  As we will see,
    however, some care is required when dealing with matrices whose
    entries are not rational numbers.  The next activity demonstrates
    how Sage can be used in this way and some of the complications
    that arise.  We will revisit this issue in subsequent sections.
    </p>

    <activity>
      <statement>
      <p> We will use Sage to find the eigenvalues and eigenvectors of
      a matrix.  Let's begin with the matrix
      <m>A = \left[\begin{array}{rr}
      1 \amp 2 \\
      2 \amp 1 \\
      \end{array}\right]
      </m>.
      <ol label="a.">
	<li><p>
	  We can find the characteristic polynomial of a
	  matrix <m>A</m> by writing 
	  <c>A.charpoly('lam')</c>.  Notice that we have to give Sage a
	  variable in which to write the polynomial;  here, we use
	  <c>lam</c> though you could just as well use <c>x</c>. </p>

	  <sage>
	    <input>
A = matrix(2,2,[1,2,2,1])
A.charpoly('lam')
	    </input>
	  </sage>

	  <p> The factored form of the characteristic polynomial may
	  be more useful since it will tell us the eigenvalues and
	  their multiplicities.  The factor chacteristic polynomial is
	  found with <c>A.fcp('lam')</c>. </p>
	  
	  <sage>
	    <input>
A = matrix(2,2,[-3,1,0,-3])
A.fcp('lam')
	    </input>
	  </sage>
	</li>

	<li><p> If we only want the eigenvalues, we can use
	<c>A.eigenvalues()</c>.  </p>

	  <sage>
	    <input>
A = matrix(2,2,[-3,1,0,-3])
A.eigenvalues()
	    </input>
	  </sage>

	  <p> Notice that the multiplicity of an eigenvalue is the
	  number of times it is repeated in the list of
	  eigenvalues. </p>
	</li>

	<li><p> Finally, we can find eigenvectors by
	<c>A.eigenvectors_right()</c>.  (We are looking for
	<em>right</em> eigenvalues since the vector <m>\vvec</m>
	appears to the right of <m>A</m> in the definition
	<m>A\vvec=\lambda \vvec</m>.) </p>
	  
	  <sage>
	    <input>
A = matrix(2,2,[-3,1,0,-3])
A.eigenvectors_right()
	    </input>
	  </sage>

	  <p> At first glance, the result of this command can be a
	  little confusing to interpret.  What we see is a list with
	  one entry for each eigenvalue.  For each eigenvalue, there
	  is a triple consisting of (i) the eigenvalue <m>\lambda</m>,
	  (ii) a basis for <m>E_\lambda</m>, and (iii) the
	  multiplicity of <m>\lambda</m>. </p> </li>

	  <li><p> When working with decimal entries, which are called
	  <em>floating point numbers</em> in computer science, we must
	  remember that computers perform only approximate arithmetic.
	  This is a problem when we wish to find the eigenvectors of such a
	  matrix.  To illustrate, consider the matrix
	  <m>A=\left[\begin{array}{rr}
	  0.4 \amp 0.3 \\
	  0.6 \amp 0.7 \\
	  \end{array}\right]
	  </m>.
	  <ol label="i.">
	    <li><p> Without using Sage, find the eigenvalues of this
	    matrix.
	    </p></li>

	    <li><p> What do you find for the reduced row echelon form
	    of <m>A-I</m>? </p></li>

	    <li><p> Let's now use Sage to determine the reduced row
	    echelon form of <m>A-I</m>: </p>
	      
	    <sage>
	      <input>
A = matrix(2,2,[0.4,0.3,0.6,0.7])
(A-identity_matrix(2)).rref()
	      </input>
	    </sage>

	    <p> What result does Sage report for the reduced row echelon
	    form?  Why is this result not correct? </p>
	    </li>
	    
	    <li><p> Because the arithmetic Sage performs with floating
	    point entries is only approximate, we are not able to find
	    the eigenspace <m>E_1</m>.  In this next chapter, we will
	    learn how to address this issue.  In the meantime,
	    we can get around this problem by writing the entries in
	    the matrix as rational numbers: </p>

	    <sage>
	      <input>
A = matrix(2,2,[4/10,3/10,6/10,7/10])
A.eigenvectors_right()
	      </input>
	    </sage>
	    </li>
	  </ol></p>
	  </li>
      </ol></p>
      </statement>
      
      <solution>
	<p><ol label="a.">
	  <li><p> The <c>fcp</c> command will return the factored
	  characteristic polynomial <c>lam^2 - 2*lam - 3</c>.
	  </p></li>

	  <li><p> The <c>eigenvalues</c> command returns a list of
	  eigenvalues <c>[-3, -3]</c>.
	  </p></li>

	  <li><p> The <c>eigenvectors_right</c> command returns
	  <c>[(-3, [(1, 0)], 2)]</c>.
	  </p></li>

	  <li><p> If we begin with the matrix <m>A</m>, we find
	  <ol label="i.">
	    <li><p> The eigenvalues are <m>\lambda=1</m> and
	    <m>\lambda=0.1</m>.
	    </p></li>

	    <li><p> The reduced row echelon form is
	    <m>\mattwo{-2}{1}{0}{0}</m>, which shows that <m>A-I</m>
	    is not invertible, as expected.
	    </p></li>

	    <li><p> Sage returns <m>\mattwo{1}{0}{0}{1}</m>, which is
	    not correct because <m>A-I</m> cannot be invertible if
	    <m>\lambda=1</m> is an eigenvalue of <m>A</m>.
	    </p></li>

	    <li><p> Here we find the correct eigenvalues,
	    <m>\lambda=1</m> with basis vector <m>\twovec{1}{2}</m>
	    for <m>E_1</m> and <m>\lambda=0.1</m> with basis vector
	    <m>\twovec{1}{-1}</m> for <m>E_{0.1}</m>.
	    </p></li>
	  </ol>
	  </p></li>
	</ol></p>
      </solution>
	    
    </activity>

  </subsection>

  
  <subsection>
    <title> Summary </title>

    <p> In this section, we developed a technique for finding the
    eigenvalues and eigenvectors of an <m>n\times n</m> matrix
    <m>A</m>. 
    <ul>
      <li><p> The expression <m>\det(A-\lambda I)</m> is a degree
      <m>n</m> polynomial, known as the characteristic polynomial.
      The eigenvalues are the roots of the characteristic
      polynomial <m>\det(A-\lambda I) = 0</m>. </p></li>

      <li><p> The set of eigenvectors associated to the eigenvalue
      <m>\lambda</m> forms the eigenspace <m>E_\lambda =
      \nul(A-\lambda I)</m>. </p></li>

      <li><p> If the factor <m>(\lambda_j - \lambda)</m> appears
      <m>m_j</m> times in the characteristic polynomial, we say that
      the eigenvalue <m>\lambda_j</m> has multiplicity <m>m_j</m> and
      note that
      <me>
	1 \leq \dim E_{\lambda_j} \leq m_j
      </me>.
      </p></li>

      <li><p> If each of the eigenvalues is real and has multiplicity
      <m>1</m>, then we can form a basis for <m>\real^n</m> consisting
      of eigenvectors of <m>A</m>. </p></li>

      <li><p> We can use Sage to find the eigenvalues and eigenvalues
      of matrices.  However, we need to be careful working with
      floating point numbers since floating point arithmetic is only
      an approximation. </p></li>
    </ul></p>
    
  </subsection>

  <xi:include href="exercises/exercises4-2.xml" />  

</section>
